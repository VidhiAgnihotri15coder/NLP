{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WE need to convert word into vectors\n",
    "#### 1) One Hot Encoding:  \n",
    "\n",
    "            unique words   --The food is good bad pizza amazing\n",
    "D1 The food is good           1    0   0  0    0    0      0 \n",
    "D2 The food is bad            0    1   0  0    0    0      0\n",
    "D3 Pizza is amazing          \n",
    "ab yahan agar D1 consider krenge ar uska one hot encoder nikalenge toh aisa kchh milega\n",
    "[[1,0,0,0,0,0,0],\n",
    " [0,1,0,0,0,0,0],\n",
    " [0,0,1,0,0,0,0],\n",
    " [0,0,0,1,0,0,0]             toh yh hai 4x7 shape , vector representation                  \n",
    "]\n",
    "\n",
    "Advantages : easy to implement with python (sklearn onehotencoder, pd.get_dummies())\n",
    "Disadvantages: \n",
    "1) sparse matrix : overfitting\n",
    "2) ML algo : we need fixed size encoding lekin idhr D4 mein shape alag ho jaaega\n",
    "3) No semantic meaning is getting captured, diff vector ka distance btaenge dimension mein toh equal dikhega but hume isse exact difference do words mein smjh nhi aaega\n",
    "4) Out of Vocabulary\n",
    "\n",
    "### 2) Bag of words \n",
    "Sabse pehle saare sentences ko lower krdo, uske baad stopwords lagado, fir frequency nikalenge vocabulary ki. Saare unique words ko use krna need nahi hota hai(repeated ko zyada use krwate hain jo ooper ooper k hain). \n",
    "Advantages: simple and intuitive, fixed size input.\n",
    "Disadvantages:\n",
    "1) Sparse matrix or array - overfitting\n",
    "2) ordering of the word gets changes\n",
    "3) Out of vocabulary \n",
    "4) Semantic mesaning still not get captured\n",
    "\n",
    "#### 3) TF-IDF [Term frequency - Inverse document frequency]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
